{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sokrypton/ColabFold/blob/main/AlphaFold2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4yBrceuFbf3"
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/sokrypton/ColabFold/main/.github/ColabFold_Marv_Logo_Small.png\" height=\"200\" align=\"right\" style=\"height:240px\">\n",
    "\n",
    "##ColabFold v1.5.5: AlphaFold2 using MMseqs2\n",
    "\n",
    "Easy to use protein structure and complex prediction using [AlphaFold2](https://www.nature.com/articles/s41586-021-03819-2) and [Alphafold2-multimer](https://www.biorxiv.org/content/10.1101/2021.10.04.463034v1). Sequence alignments/templates are generated through [MMseqs2](mmseqs.com) and [HHsearch](https://github.com/soedinglab/hh-suite). For more details, see <a href=\"#Instructions\">bottom</a> of the notebook, checkout the [ColabFold GitHub](https://github.com/sokrypton/ColabFold) and [Nature Protocols](https://www.nature.com/articles/s41596-024-01060-5).\n",
    "\n",
    "Old versions: [v1.4](https://colab.research.google.com/github/sokrypton/ColabFold/blob/v1.4.0/AlphaFold2.ipynb), [v1.5.1](https://colab.research.google.com/github/sokrypton/ColabFold/blob/v1.5.1/AlphaFold2.ipynb), [v1.5.2](https://colab.research.google.com/github/sokrypton/ColabFold/blob/v1.5.2/AlphaFold2.ipynb), [v1.5.3-patch](https://colab.research.google.com/github/sokrypton/ColabFold/blob/56c72044c7d51a311ca99b953a71e552fdc042e1/AlphaFold2.ipynb)\n",
    "\n",
    "[Mirdita M, SchÃ¼tze K, Moriwaki Y, Heo L, Ovchinnikov S, Steinegger M. ColabFold: Making protein folding accessible to all.\n",
    "*Nature Methods*, 2022](https://www.nature.com/articles/s41592-022-01488-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "kOblAo-xetgx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobname test_a5e17_0\n",
      "sequence PIAQIHILEGRSDEQKETLIREVSEAISRSLDAPLTSVRVIITEMAKGHFGIGGELASK\n",
      "length 59\n"
     ]
    }
   ],
   "source": [
    "#@title Input protein sequence(s), then hit `Runtime` -> `Run all`\n",
    "#from google.colab import files\n",
    "import os\n",
    "import re\n",
    "import hashlib\n",
    "import random\n",
    "\n",
    "from sys import version_info\n",
    "python_version = f\"{version_info.major}.{version_info.minor}\"\n",
    "\n",
    "def add_hash(x,y):\n",
    "  return x+\"_\"+hashlib.sha1(y.encode()).hexdigest()[:5]\n",
    "\n",
    "query_sequence = 'PIAQIHILEGRSDEQKETLIREVSEAISRSLDAPLTSVRVIITEMAKGHFGIGGELASK' #@param {type:\"string\"}\n",
    "#@markdown  - Use `:` to specify inter-protein chainbreaks for **modeling complexes** (supports homo- and hetro-oligomers). For example **PI...SK:PI...SK** for a homodimer\n",
    "jobname = 'test' #@param {type:\"string\"}\n",
    "# number of models to use\n",
    "num_relax = 0 #@param [0, 1, 5] {type:\"raw\"}\n",
    "#@markdown - specify how many of the top ranked structures to relax using amber\n",
    "template_mode = \"none\" #@param [\"none\", \"pdb100\",\"custom\"]\n",
    "#@markdown - `none` = no template information is used. `pdb100` = detect templates in pdb100 (see [notes](#pdb100)). `custom` - upload and search own templates (PDB or mmCIF format, see [notes](#custom_templates))\n",
    "\n",
    "use_amber = num_relax > 0\n",
    "\n",
    "# remove whitespaces\n",
    "query_sequence = \"\".join(query_sequence.split())\n",
    "\n",
    "basejobname = \"\".join(jobname.split())\n",
    "basejobname = re.sub(r'\\W+', '', basejobname)\n",
    "jobname = add_hash(basejobname, query_sequence)\n",
    "\n",
    "# check if directory with jobname exists\n",
    "def check(folder):\n",
    "  if os.path.exists(folder):\n",
    "    return False\n",
    "  else:\n",
    "    return True\n",
    "if not check(jobname):\n",
    "  n = 0\n",
    "  while not check(f\"{jobname}_{n}\"): n += 1\n",
    "  jobname = f\"{jobname}_{n}\"\n",
    "\n",
    "# make directory to save results\n",
    "os.makedirs(jobname, exist_ok=True)\n",
    "\n",
    "# save queries\n",
    "queries_path = os.path.join(jobname, f\"{jobname}.csv\")\n",
    "with open(queries_path, \"w\") as text_file:\n",
    "  text_file.write(f\"id,sequence\\n{jobname},{query_sequence}\")\n",
    "\n",
    "if template_mode == \"pdb100\":\n",
    "  use_templates = True\n",
    "  custom_template_path = None\n",
    "elif template_mode == \"custom\":\n",
    "  custom_template_path = os.path.join(jobname,f\"template\")\n",
    "  os.makedirs(custom_template_path, exist_ok=True)\n",
    "  uploaded = files.upload()\n",
    "  use_templates = True\n",
    "  for fn in uploaded.keys():\n",
    "    os.rename(fn,os.path.join(custom_template_path,fn))\n",
    "else:\n",
    "  custom_template_path = None\n",
    "  use_templates = False\n",
    "\n",
    "print(\"jobname\",jobname)\n",
    "print(\"sequence\",query_sequence)\n",
    "print(\"length\",len(query_sequence.replace(\":\",\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "id": "AzIKiDiCaHAn"
   },
   "outputs": [],
   "source": [
    "#@title Install dependencies\n",
    "#%%time\n",
    "import os\n",
    "USE_AMBER = use_amber\n",
    "USE_TEMPLATES = use_templates\n",
    "PYTHON_VERSION = python_version\n",
    "\n",
    "if not os.path.isfile(\"COLABFOLD_READY\"):\n",
    "  print(\"installing colabfold...\")\n",
    "  os.system(\"pip install -q --no-warn-conflicts 'colabfold[alphafold-minus-jax] @ git+https://github.com/sokrypton/ColabFold'\")\n",
    "  if os.environ.get('TPU_NAME', False) != False:\n",
    "    os.system(\"pip uninstall -y jax jaxlib\")\n",
    "    os.system(\"pip install --no-warn-conflicts --upgrade dm-haiku==0.0.10 'jax[cuda12_pip]'==0.3.25 -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\")\n",
    "  os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/colabfold colabfold\")\n",
    "  os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/alphafold alphafold\")\n",
    "  os.system(\"touch COLABFOLD_READY\")\n",
    "\n",
    "if USE_AMBER or USE_TEMPLATES:\n",
    "  if not os.path.isfile(\"CONDA_READY\"):\n",
    "    print(\"installing conda...\")\n",
    "    os.system(\"wget -qnc https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh\")\n",
    "    os.system(\"bash Miniforge3-Linux-x86_64.sh -bfp /usr/local\")\n",
    "    os.system(\"mamba config --set auto_update_conda false\")\n",
    "    os.system(\"touch CONDA_READY\")\n",
    "\n",
    "if USE_TEMPLATES and not os.path.isfile(\"HH_READY\") and USE_AMBER and not os.path.isfile(\"AMBER_READY\"):\n",
    "  print(\"installing hhsuite and amber...\")\n",
    "  os.system(f\"mamba install -y -c conda-forge -c bioconda kalign2=2.04 hhsuite=3.3.0 openmm=8.2.0 python='{PYTHON_VERSION}' pdbfixer\")\n",
    "  os.system(\"touch HH_READY\")\n",
    "  os.system(\"touch AMBER_READY\")\n",
    "else:\n",
    "  if USE_TEMPLATES and not os.path.isfile(\"HH_READY\"):\n",
    "    print(\"installing hhsuite...\")\n",
    "    os.system(f\"mamba install -y -c conda-forge -c bioconda kalign2=2.04 hhsuite=3.3.0 python='{PYTHON_VERSION}'\")\n",
    "    os.system(\"touch HH_READY\")\n",
    "  if USE_AMBER and not os.path.isfile(\"AMBER_READY\"):\n",
    "    print(\"installing amber...\")\n",
    "    os.system(f\"mamba install -y -c conda-forge openmm=8.2.0 python='{PYTHON_VERSION}' pdbfixer\")\n",
    "    os.system(\"touch AMBER_READY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "id": "C2_sh2uAonJH"
   },
   "outputs": [],
   "source": [
    "#@markdown ### MSA options (custom MSA upload, single sequence, pairing mode)\n",
    "msa_mode = \"mmseqs2_uniref_env\" #@param [\"mmseqs2_uniref_env\", \"mmseqs2_uniref\",\"single_sequence\",\"custom\"]\n",
    "pair_mode = \"unpaired_paired\" #@param [\"unpaired_paired\",\"paired\",\"unpaired\"] {type:\"string\"}\n",
    "#@markdown - \"unpaired_paired\" = pair sequences from same species + unpaired MSA, \"unpaired\" = seperate MSA for each chain, \"paired\" - only use paired sequences.\n",
    "\n",
    "# decide which a3m to use\n",
    "if \"mmseqs2\" in msa_mode:\n",
    "  a3m_file = os.path.join(jobname,f\"{jobname}.a3m\")\n",
    "\n",
    "elif msa_mode == \"custom\":\n",
    "  a3m_file = os.path.join(jobname,f\"{jobname}.custom.a3m\")\n",
    "  if not os.path.isfile(a3m_file):\n",
    "    custom_msa_dict = files.upload()\n",
    "    custom_msa = list(custom_msa_dict.keys())[0]\n",
    "    header = 0\n",
    "    import fileinput\n",
    "    for line in fileinput.FileInput(custom_msa,inplace=1):\n",
    "      if line.startswith(\">\"):\n",
    "         header = header + 1\n",
    "      if not line.rstrip():\n",
    "        continue\n",
    "      if line.startswith(\">\") == False and header == 1:\n",
    "         query_sequence = line.rstrip()\n",
    "      print(line, end='')\n",
    "\n",
    "    os.rename(custom_msa, a3m_file)\n",
    "    queries_path=a3m_file\n",
    "    print(f\"moving {custom_msa} to {a3m_file}\")\n",
    "\n",
    "else:\n",
    "  a3m_file = os.path.join(jobname,f\"{jobname}.single_sequence.a3m\")\n",
    "  with open(a3m_file, \"w\") as text_file:\n",
    "    text_file.write(\">1\\n%s\" % query_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "id": "ADDuaolKmjGW"
   },
   "outputs": [],
   "source": [
    "#@markdown ### Advanced settings\n",
    "model_type = \"auto\" #@param [\"auto\", \"alphafold2_ptm\", \"alphafold2_multimer_v1\", \"alphafold2_multimer_v2\", \"alphafold2_multimer_v3\", \"deepfold_v1\", \"alphafold2\"]\n",
    "#@markdown - if `auto` selected, will use `alphafold2_ptm` for monomer prediction and `alphafold2_multimer_v3` for complex prediction.\n",
    "#@markdown Any of the mode_types can be used (regardless if input is monomer or complex).\n",
    "num_recycles = \"3\" #@param [\"auto\", \"0\", \"1\", \"3\", \"6\", \"12\", \"24\", \"48\"]\n",
    "#@markdown - if `auto` selected, will use `num_recycles=20` if `model_type=alphafold2_multimer_v3`, else `num_recycles=3` .\n",
    "recycle_early_stop_tolerance = \"auto\" #@param [\"auto\", \"0.0\", \"0.5\", \"1.0\"]\n",
    "#@markdown - if `auto` selected, will use `tol=0.5` if `model_type=alphafold2_multimer_v3` else `tol=0.0`.\n",
    "relax_max_iterations = 200 #@param [0, 200, 2000] {type:\"raw\"}\n",
    "#@markdown - max amber relax iterations, `0` = unlimited (AlphaFold2 default, can take very long)\n",
    "pairing_strategy = \"greedy\" #@param [\"greedy\", \"complete\"] {type:\"string\"}\n",
    "#@markdown - `greedy` = pair any taxonomically matching subsets, `complete` = all sequences have to match in one line.\n",
    "calc_extra_ptm = False #@param {type:\"boolean\"}\n",
    "#@markdown - return pairwise chain iptm/actifptm\n",
    "\n",
    "#@markdown #### Sample settings\n",
    "#@markdown -  enable dropouts and increase number of seeds to sample predictions from uncertainty of the model.\n",
    "#@markdown -  decrease `max_msa` to increase uncertainity\n",
    "max_msa = \"auto\" #@param [\"auto\", \"512:1024\", \"256:512\", \"64:128\", \"32:64\", \"16:32\"]\n",
    "num_seeds = 1 #@param [1,2,4,8,16] {type:\"raw\"}\n",
    "use_dropout = False #@param {type:\"boolean\"}\n",
    "\n",
    "num_recycles = None if num_recycles == \"auto\" else int(num_recycles)\n",
    "recycle_early_stop_tolerance = None if recycle_early_stop_tolerance == \"auto\" else float(recycle_early_stop_tolerance)\n",
    "if max_msa == \"auto\": max_msa = None\n",
    "\n",
    "#@markdown #### Save settings\n",
    "save_all = False #@param {type:\"boolean\"}\n",
    "save_recycles = False #@param {type:\"boolean\"}\n",
    "save_to_google_drive = False #@param {type:\"boolean\"}\n",
    "#@markdown -  if the save_to_google_drive option was selected, the result zip will be uploaded to your Google Drive\n",
    "dpi = 200 #@param {type:\"integer\"}\n",
    "#@markdown - set dpi for image resolution\n",
    "\n",
    "if save_to_google_drive:\n",
    "  from pydrive2.drive import GoogleDrive\n",
    "  from pydrive2.auth import GoogleAuth\n",
    "  from google.colab import auth\n",
    "  from oauth2client.client import GoogleCredentials\n",
    "  auth.authenticate_user()\n",
    "  gauth = GoogleAuth()\n",
    "  gauth.credentials = GoogleCredentials.get_application_default()\n",
    "  drive = GoogleDrive(gauth)\n",
    "  print(\"You are logged into Google Drive and are good to go!\")\n",
    "\n",
    "#@markdown Don't forget to hit `Runtime` -> `Run all` after updating the form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting colabfold[alphafold]\n",
      "  Downloading colabfold-1.5.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting absl-py<2.0.0,>=1.0.0 (from colabfold[alphafold])\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.4 in ./.conda/lib/python3.10/site-packages (from colabfold[alphafold]) (1.4.4)\n",
      "Collecting biopython<1.83 (from colabfold[alphafold])\n",
      "  Downloading biopython-1.82-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting dm-haiku==0.0.10 (from colabfold[alphafold])\n",
      "  Downloading dm_haiku-0.0.10-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting importlib-metadata<5.0.0,>=4.8.2 (from colabfold[alphafold])\n",
      "  Downloading importlib_metadata-4.13.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting matplotlib<4.0.0,>=3.2.2 (from colabfold[alphafold])\n",
      "  Downloading matplotlib-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting numpy<2.0.0,>=1.22.0 (from colabfold[alphafold])\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting pandas<2.0.0,>=1.3.4 (from colabfold[alphafold])\n",
      "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting py3Dmol<3.0.0,>=2.0.1 (from colabfold[alphafold])\n",
      "  Downloading py3dmol-2.5.0-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.26.0 in ./.conda/lib/python3.10/site-packages (from colabfold[alphafold]) (2.32.3)\n",
      "Collecting tensorflow-cpu<3.0.0,>=2.12.1 (from colabfold[alphafold])\n",
      "  Downloading tensorflow_cpu-2.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.62.2 in ./.conda/lib/python3.10/site-packages (from colabfold[alphafold]) (4.67.1)\n",
      "Collecting alphafold-colabfold==v2.3.6 (from colabfold[alphafold])\n",
      "  Downloading alphafold_colabfold-2.3.6-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting jax<0.5.0,>=0.4.20 (from colabfold[alphafold])\n",
      "  Downloading jax-0.4.38-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting chex (from alphafold-colabfold==v2.3.6->colabfold[alphafold])\n",
      "  Downloading chex-0.1.89-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting dm-tree (from alphafold-colabfold==v2.3.6->colabfold[alphafold])\n",
      "  Downloading dm_tree-0.1.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting immutabledict (from alphafold-colabfold==v2.3.6->colabfold[alphafold])\n",
      "  Downloading immutabledict-4.2.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting ml-collections (from alphafold-colabfold==v2.3.6->colabfold[alphafold])\n",
      "  Downloading ml_collections-1.1.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting scipy (from alphafold-colabfold==v2.3.6->colabfold[alphafold])\n",
      "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting jmp>=0.0.2 (from dm-haiku==0.0.10->colabfold[alphafold])\n",
      "  Downloading jmp-0.0.4-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting tabulate>=0.8.9 (from dm-haiku==0.0.10->colabfold[alphafold])\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in ./.conda/lib/python3.10/site-packages (from importlib-metadata<5.0.0,>=4.8.2->colabfold[alphafold]) (3.22.0)\n",
      "Collecting jaxlib<=0.4.38,>=0.4.38 (from jax<0.5.0,>=0.4.20->colabfold[alphafold])\n",
      "  Downloading jaxlib-0.4.38-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting ml_dtypes>=0.4.0 (from jax<0.5.0,>=0.4.20->colabfold[alphafold])\n",
      "  Downloading ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting opt_einsum (from jax<0.5.0,>=0.4.20->colabfold[alphafold])\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib<4.0.0,>=3.2.2->colabfold[alphafold])\n",
      "  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib<4.0.0,>=3.2.2->colabfold[alphafold])\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib<4.0.0,>=3.2.2->colabfold[alphafold])\n",
      "  Downloading fonttools-4.58.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (106 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib<4.0.0,>=3.2.2->colabfold[alphafold])\n",
      "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.conda/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.2.2->colabfold[alphafold]) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib<4.0.0,>=3.2.2->colabfold[alphafold])\n",
      "  Downloading pillow-11.2.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib<4.0.0,>=3.2.2->colabfold[alphafold])\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.conda/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.2.2->colabfold[alphafold]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.conda/lib/python3.10/site-packages (from pandas<2.0.0,>=1.3.4->colabfold[alphafold]) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.26.0->colabfold[alphafold]) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.26.0->colabfold[alphafold]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.26.0->colabfold[alphafold]) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.26.0->colabfold[alphafold]) (2025.4.26)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-cpu<3.0.0,>=2.12.1->colabfold[alphafold])\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-cpu<3.0.0,>=2.12.1->colabfold[alphafold])\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-cpu<3.0.0,>=2.12.1->colabfold[alphafold])\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-cpu<3.0.0,>=2.12.1->colabfold[alphafold])\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-cpu<3.0.0,>=2.12.1->colabfold[alphafold])\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow-cpu<3.0.0,>=2.12.1->colabfold[alphafold])\n",
      "  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: setuptools in ./.conda/lib/python3.10/site-packages (from tensorflow-cpu<3.0.0,>=2.12.1->colabfold[alphafold]) (78.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.conda/lib/python3.10/site-packages (from tensorflow-cpu<3.0.0,>=2.12.1->colabfold[alphafold]) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-cpu<3.0.0,>=2.12.1->colabfold[alphafold])\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./.conda/lib/python3.10/site-packages (from tensorflow-cpu<3.0.0,>=2.12.1->colabfold[alphafold]) (4.14.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-cpu<3.0.0,>=2.12.1->colabfold[alphafold])\n",
      "  Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-cpu<3.0.0,>=2.12.1->colabfold[alphafold])\n",
      "  Downloading grpcio-1.72.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow-cpu<3.0.0,>=2.12.1->colabfold[alphafold])\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow-cpu<3.0.0,>=2.12.1->colabfold[alphafold])\n",
      "  Downloading keras-3.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow-cpu<3.0.0,>=2.12.1->colabfold[alphafold])\n",
      "  Downloading h5py-3.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-cpu<3.0.0,>=2.12.1->colabfold[alphafold])\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow-cpu<3.0.0,>=2.12.1->colabfold[alphafold])\n",
      "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow-cpu<3.0.0,>=2.12.1->colabfold[alphafold])\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow-cpu<3.0.0,>=2.12.1->colabfold[alphafold])\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-cpu<3.0.0,>=2.12.1->colabfold[alphafold]) (0.45.1)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow-cpu<3.0.0,>=2.12.1->colabfold[alphafold])\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow-cpu<3.0.0,>=2.12.1->colabfold[alphafold])\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow-cpu<3.0.0,>=2.12.1->colabfold[alphafold])\n",
      "  Downloading optree-0.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (30 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow-cpu<3.0.0,>=2.12.1->colabfold[alphafold])\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting toolz>=0.9.0 (from chex->alphafold-colabfold==v2.3.6->colabfold[alphafold])\n",
      "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=18.2.0 (from dm-tree->alphafold-colabfold==v2.3.6->colabfold[alphafold])\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting PyYAML (from ml-collections->alphafold-colabfold==v2.3.6->colabfold[alphafold])\n",
      "  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow-cpu<3.0.0,>=2.12.1->colabfold[alphafold])\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.conda/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow-cpu<3.0.0,>=2.12.1->colabfold[alphafold]) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-cpu<3.0.0,>=2.12.1->colabfold[alphafold])\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading colabfold-1.5.5-py3-none-any.whl (65 kB)\n",
      "Downloading alphafold_colabfold-2.3.6-py3-none-any.whl (242 kB)\n",
      "Downloading dm_haiku-0.0.10-py3-none-any.whl (360 kB)\n",
      "Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Downloading biopython-1.82-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
      "Downloading jax-0.4.38-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jaxlib-0.4.38-cp310-cp310-manylinux2014_x86_64.whl (101.7 MB)\n",
      "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m101.7/101.7 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hDownloading matplotlib-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading py3dmol-2.5.0-py2.py3-none-any.whl (7.2 kB)\n",
      "Downloading tensorflow_cpu-2.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (251.6 MB)\n",
      "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m251.6/251.6 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.72.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading fonttools-4.58.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m107.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m108.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jmp-0.0.4-py3-none-any.whl (18 kB)\n",
      "Downloading keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m107.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading pillow-11.2.1-cp310-cp310-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m108.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
      "Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
      "Downloading chex-0.1.89-py3-none-any.whl (99 kB)\n",
      "Downloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
      "Downloading dm_tree-0.1.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading immutabledict-4.2.1-py3-none-any.whl (4.7 kB)\n",
      "Downloading ml_collections-1.1.0-py3-none-any.whl (76 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (405 kB)\n",
      "Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
      "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m751.2/751.2 kB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: py3Dmol, namex, libclang, flatbuffers, wrapt, toolz, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, tabulate, PyYAML, pyparsing, protobuf, pillow, optree, opt_einsum, numpy, mdurl, MarkupSafe, markdown, kiwisolver, importlib-metadata, immutabledict, grpcio, google-pasta, gast, fonttools, cycler, attrs, astunparse, absl-py, werkzeug, scipy, pandas, ml_dtypes, ml-collections, markdown-it-py, jmp, h5py, dm-tree, contourpy, biopython, tensorboard, rich, matplotlib, jaxlib, dm-haiku, keras, jax, tensorflow-cpu, chex, colabfold, alphafold-colabfold\n",
      "\u001b[?25l"
     ]
    }
   ],
   "source": [
    "#!pip install Bio\n",
    "#!pip install appdirs\n",
    "#!pip install absl-py\n",
    "#!pip install importlib_metadata\n",
    "!pip install colabfold[alphafold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cellView": "form",
    "id": "mbaIO9pWjaN0"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\n\nalphafold is not installed. Please run `pip install colabfold[alphafold]`\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/mnt/code/colabfold/batch.py:31\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 31\u001b[0m     \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39malphafold\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mModuleNotFoundError\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'alphafold'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/mnt/code/AlphaFold2.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://domino-glue01.pg.wwtatc.ai/mnt/code/AlphaFold2.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcolabfold\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdownload\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m download_alphafold_params, default_data_dir\n\u001b[1;32m     <a href='vscode-notebook-cell://domino-glue01.pg.wwtatc.ai/mnt/code/AlphaFold2.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcolabfold\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m setup_logging\n\u001b[0;32m---> <a href='vscode-notebook-cell://domino-glue01.pg.wwtatc.ai/mnt/code/AlphaFold2.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcolabfold\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbatch\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m get_queries, run, set_model_type\n\u001b[1;32m     <a href='vscode-notebook-cell://domino-glue01.pg.wwtatc.ai/mnt/code/AlphaFold2.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcolabfold\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplot\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m plot_msa_v2\n\u001b[1;32m     <a href='vscode-notebook-cell://domino-glue01.pg.wwtatc.ai/mnt/code/AlphaFold2.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mos\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/code/colabfold/batch.py:33\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39malphafold\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mModuleNotFoundError\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m     34\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39malphafold is not installed. Please run `pip install colabfold[alphafold]`\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     35\u001b[0m     )\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39malphafold\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mimport\u001b[39;00m protein, residue_constants\n\u001b[1;32m     39\u001b[0m \u001b[39m# delay imports of tensorflow, jax and numpy\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39m# loading these for type checking only can take around 10 seconds just to show a CLI usage message\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \n\nalphafold is not installed. Please run `pip install colabfold[alphafold]`\n"
     ]
    }
   ],
   "source": [
    "#@title Run Prediction\n",
    "display_images = True #@param {type:\"boolean\"}\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from Bio import BiopythonDeprecationWarning\n",
    "warnings.simplefilter(action='ignore', category=BiopythonDeprecationWarning)\n",
    "from pathlib import Path\n",
    "from colabfold.download import download_alphafold_params, default_data_dir\n",
    "from colabfold.utils import setup_logging\n",
    "from colabfold.batch import get_queries, run, set_model_type\n",
    "from colabfold.plot import plot_msa_v2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "try:\n",
    "  K80_chk = os.popen('nvidia-smi | grep \"Tesla K80\" | wc -l').read()\n",
    "except:\n",
    "  K80_chk = \"0\"\n",
    "  pass\n",
    "if \"1\" in K80_chk:\n",
    "  print(\"WARNING: found GPU Tesla K80: limited to total length < 1000\")\n",
    "  if \"TF_FORCE_UNIFIED_MEMORY\" in os.environ:\n",
    "    del os.environ[\"TF_FORCE_UNIFIED_MEMORY\"]\n",
    "  if \"XLA_PYTHON_CLIENT_MEM_FRACTION\" in os.environ:\n",
    "    del os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]\n",
    "\n",
    "from colabfold.colabfold import plot_protein\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For some reason we need that to get pdbfixer to import\n",
    "if use_amber and f\"/usr/local/lib/python{python_version}/site-packages/\" not in sys.path:\n",
    "    sys.path.insert(0, f\"/usr/local/lib/python{python_version}/site-packages/\")\n",
    "\n",
    "def input_features_callback(input_features):\n",
    "  if display_images:\n",
    "    plot_msa_v2(input_features)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def prediction_callback(protein_obj, length,\n",
    "                        prediction_result, input_features, mode):\n",
    "  model_name, relaxed = mode\n",
    "  if not relaxed:\n",
    "    if display_images:\n",
    "      fig = plot_protein(protein_obj, Ls=length, dpi=150)\n",
    "      plt.show()\n",
    "      plt.close()\n",
    "\n",
    "result_dir = jobname\n",
    "log_filename = os.path.join(jobname,\"log.txt\")\n",
    "setup_logging(Path(log_filename))\n",
    "\n",
    "queries, is_complex = get_queries(queries_path)\n",
    "model_type = set_model_type(is_complex, model_type)\n",
    "\n",
    "if \"multimer\" in model_type and max_msa is not None:\n",
    "  use_cluster_profile = False\n",
    "else:\n",
    "  use_cluster_profile = True\n",
    "\n",
    "download_alphafold_params(model_type, Path(\".\"))\n",
    "results = run(\n",
    "    queries=queries,\n",
    "    result_dir=result_dir,\n",
    "    use_templates=use_templates,\n",
    "    custom_template_path=custom_template_path,\n",
    "    num_relax=num_relax,\n",
    "    msa_mode=msa_mode,\n",
    "    model_type=model_type,\n",
    "    num_models=5,\n",
    "    num_recycles=num_recycles,\n",
    "    relax_max_iterations=relax_max_iterations,\n",
    "    recycle_early_stop_tolerance=recycle_early_stop_tolerance,\n",
    "    num_seeds=num_seeds,\n",
    "    use_dropout=use_dropout,\n",
    "    model_order=[1,2,3,4,5],\n",
    "    is_complex=is_complex,\n",
    "    data_dir=Path(\".\"),\n",
    "    keep_existing_results=False,\n",
    "    rank_by=\"auto\",\n",
    "    pair_mode=pair_mode,\n",
    "    pairing_strategy=pairing_strategy,\n",
    "    stop_at_score=float(100),\n",
    "    prediction_callback=prediction_callback,\n",
    "    dpi=dpi,\n",
    "    zip_results=False,\n",
    "    save_all=save_all,\n",
    "    max_msa=max_msa,\n",
    "    use_cluster_profile=use_cluster_profile,\n",
    "    input_features_callback=input_features_callback,\n",
    "    save_recycles=save_recycles,\n",
    "    user_agent=\"colabfold/google-colab-main\",\n",
    "    calc_extra_ptm=calc_extra_ptm,\n",
    ")\n",
    "results_zip = f\"{jobname}.result.zip\"\n",
    "os.system(f\"zip -r {results_zip} {jobname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "KK7X9T44pWb7"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'py3Dmol'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#@title Display 3D structure {run: \"auto\"}\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpy3Dmol\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mglob\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'py3Dmol'"
     ]
    }
   ],
   "source": [
    "#@title Display 3D structure {run: \"auto\"}\n",
    "import py3Dmol\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from colabfold.colabfold import plot_plddt_legend\n",
    "from colabfold.colabfold import pymol_color_list, alphabet_list\n",
    "rank_num = 1 #@param [\"1\", \"2\", \"3\", \"4\", \"5\"] {type:\"raw\"}\n",
    "color = \"lDDT\" #@param [\"chain\", \"lDDT\", \"rainbow\"]\n",
    "show_sidechains = False #@param {type:\"boolean\"}\n",
    "show_mainchains = False #@param {type:\"boolean\"}\n",
    "\n",
    "tag = results[\"rank\"][0][rank_num - 1]\n",
    "jobname_prefix = \".custom\" if msa_mode == \"custom\" else \"\"\n",
    "pdb_filename = f\"{jobname}/{jobname}{jobname_prefix}_unrelaxed_{tag}.pdb\"\n",
    "pdb_file = glob.glob(pdb_filename)\n",
    "\n",
    "def show_pdb(rank_num=1, show_sidechains=False, show_mainchains=False, color=\"lDDT\"):\n",
    "  model_name = f\"rank_{rank_num}\"\n",
    "  view = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js',)\n",
    "  view.addModel(open(pdb_file[0],'r').read(),'pdb')\n",
    "\n",
    "  if color == \"lDDT\":\n",
    "    view.setStyle({'cartoon': {'colorscheme': {'prop':'b','gradient': 'roygb','min':50,'max':90}}})\n",
    "  elif color == \"rainbow\":\n",
    "    view.setStyle({'cartoon': {'color':'spectrum'}})\n",
    "  elif color == \"chain\":\n",
    "    chains = len(queries[0][1]) + 1 if is_complex else 1\n",
    "    for n,chain,color in zip(range(chains),alphabet_list,pymol_color_list):\n",
    "       view.setStyle({'chain':chain},{'cartoon': {'color':color}})\n",
    "\n",
    "  if show_sidechains:\n",
    "    BB = ['C','O','N']\n",
    "    view.addStyle({'and':[{'resn':[\"GLY\",\"PRO\"],'invert':True},{'atom':BB,'invert':True}]},\n",
    "                        {'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
    "    view.addStyle({'and':[{'resn':\"GLY\"},{'atom':'CA'}]},\n",
    "                        {'sphere':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
    "    view.addStyle({'and':[{'resn':\"PRO\"},{'atom':['C','O'],'invert':True}]},\n",
    "                        {'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
    "  if show_mainchains:\n",
    "    BB = ['C','O','N','CA']\n",
    "    view.addStyle({'atom':BB},{'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
    "\n",
    "  view.zoomTo()\n",
    "  return view\n",
    "\n",
    "show_pdb(rank_num, show_sidechains, show_mainchains, color).show()\n",
    "if color == \"lDDT\":\n",
    "  plot_plddt_legend().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "11l8k--10q0C"
   },
   "outputs": [],
   "source": [
    "#@title Plots {run: \"auto\"}\n",
    "from IPython.display import display, HTML\n",
    "import base64\n",
    "from html import escape\n",
    "\n",
    "# see: https://stackoverflow.com/a/53688522\n",
    "def image_to_data_url(filename):\n",
    "  ext = filename.split('.')[-1]\n",
    "  prefix = f'data:image/{ext};base64,'\n",
    "  with open(filename, 'rb') as f:\n",
    "    img = f.read()\n",
    "  return prefix + base64.b64encode(img).decode('utf-8')\n",
    "\n",
    "pae = \"\"\n",
    "pae_file = os.path.join(jobname,f\"{jobname}{jobname_prefix}_pae.png\")\n",
    "if os.path.isfile(pae_file):\n",
    "    pae = image_to_data_url(pae_file)\n",
    "cov = image_to_data_url(os.path.join(jobname,f\"{jobname}{jobname_prefix}_coverage.png\"))\n",
    "plddt = image_to_data_url(os.path.join(jobname,f\"{jobname}{jobname_prefix}_plddt.png\"))\n",
    "display(HTML(f\"\"\"\n",
    "<style>\n",
    "  img {{\n",
    "    float:left;\n",
    "  }}\n",
    "  .full {{\n",
    "    max-width:100%;\n",
    "  }}\n",
    "  .half {{\n",
    "    max-width:50%;\n",
    "  }}\n",
    "  @media (max-width:640px) {{\n",
    "    .half {{\n",
    "      max-width:100%;\n",
    "    }}\n",
    "  }}\n",
    "</style>\n",
    "<div style=\"max-width:90%; padding:2em;\">\n",
    "  <h1>Plots for {escape(jobname)}</h1>\n",
    "  { '<!--' if pae == '' else '' }<img src=\"{pae}\" class=\"full\" />{ '-->' if pae == '' else '' }\n",
    "  <img src=\"{cov}\" class=\"half\" />\n",
    "  <img src=\"{plddt}\" class=\"half\" />\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "R_AH6JSXaeb2"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'msa_mode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#@title Package and download results\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#@markdown If you are having issues downloading the result archive, try disabling your adblocker and run this cell again. If that fails click on the little folder icon to the left, navigate to file: `jobname.result.zip`, right-click and select \\\"Download\\\" (see [screenshot](https://pbs.twimg.com/media/E6wRW2lWUAEOuoe?format=jpg&name=small)).\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmsa_mode\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      5\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDon\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt forget to cite your custom MSA generation method.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m files\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjobname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.result.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'msa_mode' is not defined"
     ]
    }
   ],
   "source": [
    "#@title Package and download results\n",
    "#@markdown If you are having issues downloading the result archive, try disabling your adblocker and run this cell again. If that fails click on the little folder icon to the left, navigate to file: `jobname.result.zip`, right-click and select \\\"Download\\\" (see [screenshot](https://pbs.twimg.com/media/E6wRW2lWUAEOuoe?format=jpg&name=small)).\n",
    "\n",
    "if msa_mode == \"custom\":\n",
    "  print(\"Don't forget to cite your custom MSA generation method.\")\n",
    "\n",
    "files.download(f\"{jobname}.result.zip\")\n",
    "\n",
    "if save_to_google_drive == True and drive:\n",
    "  uploaded = drive.CreateFile({'title': f\"{jobname}.result.zip\"})\n",
    "  uploaded.SetContentFile(f\"{jobname}.result.zip\")\n",
    "  uploaded.Upload()\n",
    "  print(f\"Uploaded {jobname}.result.zip to Google Drive with ID {uploaded.get('id')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGUBLzB3C6WN",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Instructions <a name=\"Instructions\"></a>\n",
    "For detailed instructions, tips and tricks, see recently published paper at [Nature Protocols](https://www.nature.com/articles/s41596-024-01060-5)\n",
    "\n",
    "**Quick start**\n",
    "1. Paste your protein sequence(s) in the input field.\n",
    "2. Press \"Runtime\" -> \"Run all\".\n",
    "3. The pipeline consists of 5 steps. The currently running step is indicated by a circle with a stop sign next to it.\n",
    "\n",
    "**Result zip file contents**\n",
    "\n",
    "1. PDB formatted structures sorted by avg. pLDDT and complexes are sorted by pTMscore. (unrelaxed and relaxed if `use_amber` is enabled).\n",
    "2. Plots of the model quality.\n",
    "3. Plots of the MSA coverage.\n",
    "4. Parameter log file.\n",
    "5. A3M formatted input MSA.\n",
    "6. A `predicted_aligned_error_v1.json` using [AlphaFold-DB's format](https://alphafold.ebi.ac.uk/faq#faq-7) and a `scores.json` for each model which contains an array (list of lists) for PAE, a list with the average pLDDT and the pTMscore.\n",
    "7. BibTeX file with citations for all used tools and databases.\n",
    "\n",
    "At the end of the job a download modal box will pop up with a `jobname.result.zip` file. Additionally, if the `save_to_google_drive` option was selected, the `jobname.result.zip` will be uploaded to your Google Drive.\n",
    "\n",
    "**MSA generation for complexes**\n",
    "\n",
    "For the complex prediction we use unpaired and paired MSAs. Unpaired MSA is generated the same way as for the protein structures prediction by searching the UniRef100 and environmental sequences three iterations each.\n",
    "\n",
    "The paired MSA is generated by searching the UniRef100 database and pairing the best hits sharing the same NCBI taxonomic identifier (=species or sub-species). We only pair sequences if all of the query sequences are present for the respective taxonomic identifier.\n",
    "\n",
    "**Using a custom MSA as input**\n",
    "\n",
    "To predict the structure with a custom MSA (A3M formatted): (1) Change the `msa_mode`: to \"custom\", (2) Wait for an upload box to appear at the end of the \"MSA options ...\" box. Upload your A3M. The first fasta entry of the A3M must be the query sequence without gaps.\n",
    "\n",
    "It is also possilbe to provide custom MSAs for complex predictions. Read more about the format [here](https://github.com/sokrypton/ColabFold/issues/76).\n",
    "\n",
    "As an alternative for MSA generation the [HHblits Toolkit server](https://toolkit.tuebingen.mpg.de/tools/hhblits) can be used. After submitting your query, click \"Query Template MSA\" -> \"Download Full A3M\". Download the A3M file and upload it in this notebook.\n",
    "\n",
    "**PDB100** <a name=\"pdb100\"></a>\n",
    "\n",
    "As of 23/06/08, we have transitioned from using the PDB70 to a 100% clustered PDB, the PDB100. The construction methodology of PDB100 differs from that of PDB70.\n",
    "\n",
    "The PDB70 was constructed by running each PDB70 representative sequence through [HHblits](https://github.com/soedinglab/hh-suite) against the [Uniclust30](https://uniclust.mmseqs.com/). On the other hand, the PDB100 is built by searching each PDB100 representative structure with [Foldseek](https://github.com/steineggerlab/foldseek) against the [AlphaFold Database](https://alphafold.ebi.ac.uk).\n",
    "\n",
    "To maintain compatibility with older Notebook versions and local installations, the generated files and API responses will continue to be named \"PDB70\", even though we're now using the PDB100.\n",
    "\n",
    "**Using custom templates** <a name=\"custom_templates\"></a>\n",
    "\n",
    "To predict the structure with a custom template (PDB or mmCIF formatted): (1) change the `template_mode` to \"custom\" in the execute cell and (2) wait for an upload box to appear at the end of the \"Input Protein\" box. Select and upload your templates (multiple choices are possible).\n",
    "\n",
    "* Templates must follow the four letter PDB naming with lower case letters.\n",
    "\n",
    "* Templates in mmCIF format must contain `_entity_poly_seq`. An error is thrown if this field is not present. The field `_pdbx_audit_revision_history.revision_date` is automatically generated if it is not present.\n",
    "\n",
    "* Templates in PDB format are automatically converted to the mmCIF format. `_entity_poly_seq` and `_pdbx_audit_revision_history.revision_date` are automatically generated.\n",
    "\n",
    "If you encounter problems, please report them to this [issue](https://github.com/sokrypton/ColabFold/issues/177).\n",
    "\n",
    "**Comparison to the full AlphaFold2 and AlphaFold2 Colab**\n",
    "\n",
    "This notebook replaces the homology detection and MSA pairing of AlphaFold2 with MMseqs2. For a comparison against the [AlphaFold2 Colab](https://colab.research.google.com/github/deepmind/alphafold/blob/main/notebooks/AlphaFold.ipynb) and the full [AlphaFold2](https://github.com/deepmind/alphafold) system read our [paper](https://www.nature.com/articles/s41592-022-01488-1).\n",
    "\n",
    "**Troubleshooting**\n",
    "* Check that the runtime type is set to GPU at \"Runtime\" -> \"Change runtime type\".\n",
    "* Try to restart the session \"Runtime\" -> \"Factory reset runtime\".\n",
    "* Check your input sequence.\n",
    "\n",
    "**Known issues**\n",
    "* Google Colab assigns different types of GPUs with varying amount of memory. Some might not have enough memory to predict the structure for a long sequence.\n",
    "* Your browser can block the pop-up for downloading the result file. You can choose the `save_to_google_drive` option to upload to Google Drive instead or manually download the result file: Click on the little folder icon to the left, navigate to file: `jobname.result.zip`, right-click and select \\\"Download\\\" (see [screenshot](https://pbs.twimg.com/media/E6wRW2lWUAEOuoe?format=jpg&name=small)).\n",
    "\n",
    "**Limitations**\n",
    "* Computing resources: Our MMseqs2 API can handle ~20-50k requests per day.\n",
    "* MSAs: MMseqs2 is very precise and sensitive but might find less hits compared to HHblits/HMMer searched against BFD or MGnify.\n",
    "* We recommend to additionally use the full [AlphaFold2 pipeline](https://github.com/deepmind/alphafold).\n",
    "\n",
    "**Description of the plots**\n",
    "*   **Number of sequences per position** - We want to see at least 30 sequences per position, for best performance, ideally 100 sequences.\n",
    "*   **Predicted lDDT per position** - model confidence (out of 100) at each position. The higher the better.\n",
    "*   **Predicted Alignment Error** - For homooligomers, this could be a useful metric to assess how confident the model is about the interface. The lower the better.\n",
    "\n",
    "**Bugs**\n",
    "- If you encounter any bugs, please report the issue to https://github.com/sokrypton/ColabFold/issues\n",
    "\n",
    "**License**\n",
    "\n",
    "The source code of ColabFold is licensed under [MIT](https://raw.githubusercontent.com/sokrypton/ColabFold/main/LICENSE). Additionally, this notebook uses the AlphaFold2 source code and its parameters licensed under [Apache 2.0](https://raw.githubusercontent.com/deepmind/alphafold/main/LICENSE) and [CC BY 4.0](https://creativecommons.org/licenses/by-sa/4.0/) respectively. Read more about the AlphaFold license [here](https://github.com/deepmind/alphafold).\n",
    "\n",
    "**Acknowledgments**\n",
    "- We thank the AlphaFold team for developing an excellent model and open sourcing the software.\n",
    "\n",
    "- [KOBIC](https://kobic.re.kr) and [SÃ¶ding Lab](https://www.mpinat.mpg.de/soeding) for providing the computational resources for the MMseqs2 MSA server.\n",
    "\n",
    "- Richard Evans for helping to benchmark the ColabFold's Alphafold-multimer support.\n",
    "\n",
    "- [David Koes](https://github.com/dkoes) for his awesome [py3Dmol](https://3dmol.csb.pitt.edu/) plugin, without whom these notebooks would be quite boring!\n",
    "\n",
    "- Do-Yoon Kim for creating the ColabFold logo.\n",
    "\n",
    "- A colab by Sergey Ovchinnikov ([@sokrypton](https://twitter.com/sokrypton)), Milot Mirdita ([@milot_mirdita](https://twitter.com/milot_mirdita)) and Martin Steinegger ([@thesteinegger](https://twitter.com/thesteinegger)).\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
